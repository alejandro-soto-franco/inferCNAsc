# -*- coding: utf-8 -*-
"""finalcode_amyedit_v2.ipynb

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/1PYleg4iaqnrmsIOLm9XQkFDpEoX_WCLR

# Task 1

## **Installing packages and importing the scRNAseq and test data.**

We will use the test data and 2D gastruloid scRNAseq data for our tool development and assessments.
"""

from google.colab import drive
drive.mount('/content/drive')

import os, sys
os.environ['R_HOME'] = sys.exec_prefix+"/lib/R/"
!pip install scanpy
!pip install scFates

import scanpy as sc
import scFates as scf
import numpy as np
import pandas as pd

!pip install git+https://github.com/pcahan1/PySingleCellNet/
!pip install scikit-misc
!pip install -q git+https://github.com/theislab/cellrank
!pip install git+https://github.com/CahanLab/oneSC.git

import matplotlib.pyplot as plt
import pySingleCellNet as cn
import skmisc
import scvelo as scv
import cellrank as cr
import onesc
import networkx as nx
import warnings

"""**Importing the test PBMC data**

"""

# import and clean up data

cna_bench = sc.read_h5ad('/content/drive/MyDrive/CSCB_HW/final/PBMC_simulated_cnas_041025.h5ad')
cna_bench.var_names_make_unique()

print(cna_bench.var.head(30))

"""**Importing the 2D gastruloid scRNAseq data**

"""

#import 2D gastruloid PSCs scRNAseq data
data1 = sc.read_h5ad('/content/drive/MyDrive/CSCB_HW/final/data1_GSM8633801_adata_timeseries_new_D6-10_filtered_qc.h5ad')
data1.var_names_make_unique()

print(data1.var.head(30))

print(type(data1.X))
print(data1.X.shape)         # Should be (n_cells, n_genes)
print(data1.X[:5, :5])       # View first 5 cells × first 5 genes

print(data1.raw)  # If not None, raw counts might be stored here
print(data1.X[:5, :5].toarray())  # Show a small part of the matrix
print(data1.shape)

"""**scRNAseq data gene annotations**

Since the 2d gastruloid data and many other .h5ad scRNAseq data files typically only store gene names and raw expression, we will first need to query positions and annotations for each of the genes in the dataset. We created a function for this specifically (called add_gene_coordinates) that annotates each gene's chromosome location and start/end positions on the chromosome. These locations will be used later for binning in CNA detection.
"""

!pip install pybiomart

def add_gene_coordinates(adata):
    from pybiomart import Server

    # Connect to Ensembl via BioMart
    server = Server(host='http://www.ensembl.org')
    dataset = server.marts['ENSEMBL_MART_ENSEMBL'].datasets['hsapiens_gene_ensembl']

    # Query BioMart
    gene_ids = [g.split('(')[-1].strip(')') if '(' in g else g for g in adata.var_names]
    results = dataset.query(attributes=[
        'ensembl_gene_id', 'external_gene_name',
        'chromosome_name', 'start_position', 'end_position'
    ])
    results = results.set_index('Gene stable ID')

    # Match back to AnnData
    adata.var['ensembl'] = gene_ids
    adata.var = adata.var.join(results, on='ensembl')
    adata.var.rename(columns={
        'Chromosome/scaffold name': 'chromosome',
        'Gene start (bp)': 'start',
        'Gene end (bp)': 'end',
        'Gene name': 'symbol'
    }, inplace=True)

    return adata

data1 = add_gene_coordinates(data1)

print(data1.var.columns)
print(data1.var['chromosome'].notna().sum(), "genes have coordinates")
print(data1.var[['chromosome', 'start', 'end']].head(10))

"""## **Quality control of the data.**

We also will need to perform quality control on both datasets similar to past homeworks.
"""

def run_qc(adata, min_genes=3000, max_counts=25000, min_cells=3, max_pct_mt=2, max_pct_ribo=3):
    adata_qc = adata.copy()

    adata_qc.var['mt'] = adata_qc.var_names.str.upper().str.startswith('MT-')
    ribo_prefix = ('RPS', 'RPL')
    adata_qc.var['ribo'] = adata_qc.var_names.str.upper().str.startswith(ribo_prefix)

    sc.pp.calculate_qc_metrics(adata_qc, qc_vars=['mt', 'ribo'], inplace=True)

    # Plot QC metrics
    fig, axs = plt.subplots(1, 3, figsize=(15, 4))
    sc.pl.scatter(adata_qc, x='total_counts', y='n_genes_by_counts', ax=axs[0], show=False)
    sc.pl.scatter(adata_qc, x='total_counts', y='pct_counts_mt', ax=axs[1], show=False)
    sc.pl.scatter(adata_qc, x='total_counts', y='pct_counts_ribo', ax=axs[2], show=False)
    plt.tight_layout()
    plt.show()

    # Apply filters
    sc.pp.filter_cells(adata_qc, min_genes=min_genes)
    sc.pp.filter_cells(adata_qc, max_counts=max_counts)
    sc.pp.filter_genes(adata_qc, min_cells=min_cells)

    adata_qc.raw = adata_qc

    # Remove cells with high mitochondrial or ribosomal content
    adata_qc = adata_qc[adata_qc.obs['pct_counts_mt'] < max_pct_mt, :]
    adata_qc = adata_qc[adata_qc.obs['pct_counts_ribo'] < max_pct_ribo, :]

    # Normalize and log1p transform
    sc.pp.normalize_total(adata_qc, target_sum=1e4)
    sc.pp.log1p(adata_qc)

    print("Original shape:", adata.shape)
    print("QC-filtered shape:", adata_qc.shape)
    removed_cells = adata.shape[0] - adata_qc.shape[0]
    print(f"Number of cells removed by QC: {removed_cells}")

    return adata_qc

data1_norm = run_qc(data1)

cna_bench_norm = run_qc(cna_bench, min_genes=500, max_counts=20000, min_cells=3)

"""## **CNA identification tool**

Our method introduces several innovations and improvements of previous CNA inference tools that will allow successful inference on scRNAseq data.

1) Automatic within-sample reference baseline based on transcriptional profile clustering

While previous tools like inferCNV rely on an external, user-defined reference or an internal reference based on the average gene expression values globally (can be external as well from a separate dataset), our method will introduce an automatic reference cell selection based on unsupervised clustering. We will cluster the cells and calculate each cluster's average gene expression before comparing it to the mean expression of the other clusters combined. We can then calculate a z-score that indicates how much the cluster deviates from the rest of the population and use that difference to infer CNAs.

This selection process will hopefully minimize false positives that may occur from the tool calling a region a CNA insertion/deletion when it could be a transcriptional increase or decrease in gene expression. It will also capture any biological variability better than taking a global average gene expression, giving potentially a more refined detection methodology. This can be especially useful for highly heterogenous settings like pluripotent stem cells where the dataset may have no truly diploid cells to act as a baseline reference.

https://infercnvpy.readthedocs.io/en/latest/infercnv.html

### Unsupervised clustering of the datasets.
"""

!pip install scanpy scipy umap-learn leidenalg

def perform_clustering(adata, adata_name, resolution=0.1):
    np.random.seed(42)
    sc.pp.highly_variable_genes(adata, n_top_genes=2000, flavor="cell_ranger")
    adata_hvg = adata[:, adata.var["highly_variable"]].copy()

    sc.pp.pca(adata_hvg)
    sc.pp.neighbors(adata_hvg, n_neighbors=10, n_pcs=20)
    sc.tl.leiden(adata_hvg, resolution=resolution)
    adata.obs['leiden'] = adata_hvg.obs['leiden']
    sc.tl.umap(adata_hvg)

    sc.pl.umap(adata_hvg, color='leiden', title=f'Leiden Clustering for {adata_name}')

    return adata_hvg

data1_pca_norm = perform_clustering(data1_norm, adata_name = '2D Gastruloid Data')
cna_bench_pca_norm = perform_clustering(cna_bench_norm, adata_name = 'PBMC Test Data')

def infer_cnv_h5ad(adata, group_by='leiden', z_thresh=1.5, verbose=True):

    from scipy.sparse import issparse

    adata = adata.copy()
    X = adata.X.toarray() if issparse(adata.X) else adata.X
    gene_names = adata.var_names
    cluster_labels = adata.obs[group_by].astype(str)
    clusters = cluster_labels.unique()

    cnv_calls = pd.DataFrame(index=adata.obs_names, columns=gene_names)

    for cluster in clusters:
        cluster_cells = cluster_labels[cluster_labels == cluster].index
        other_cells = cluster_labels[cluster_labels != cluster].index

        X_cluster = adata[cluster_cells].X.toarray() if issparse(adata[cluster_cells].X) else adata[cluster_cells].X
        X_other = adata[other_cells].X.toarray() if issparse(adata[other_cells].X) else adata[other_cells].X

        mean_cluster = X_cluster.mean(axis=0)
        mean_other = X_other.mean(axis=0)
        std_other = X_other.std(axis=0) + 1e-6

        zscores = (mean_cluster - mean_other) / std_other
        calls = np.where(zscores > z_thresh, 'gain',
                 np.where(zscores < -z_thresh, 'loss', 'neutral'))

        for cell in cluster_cells:
            cnv_calls.loc[cell] = calls

        if verbose:
            print(f"Cluster {cluster} done. N_cells: {len(cluster_cells)}")

    adata.obsm['cnv_calls'] = cnv_calls

    return adata

data1_cnv = infer_cnv_h5ad(data1_pca_norm)
data1_cnv.write("data1_cnv.h5ad")

from google.colab import files
files.download("data1_cnv.h5ad")

print(data1_pca_norm.obs['leiden'].value_counts())
print(data1_pca_norm.obs['leiden'].value_counts().sum())

print(cna_bench_pca_norm.obs['leiden'].value_counts())  # Check the clusters for cna_bench
print(cna_bench_pca_norm.obs['leiden'].value_counts().sum())

print("data1.obs shape:", data1_pca_norm.obs.shape)  # Should match number of cells
print("data1.obsm['X_pca'] shape:", data1_pca_norm.obsm['X_pca'].shape)  # Should match number of cells

data1_final, data1_summary = infer_cnv_clustering(data1_pca_norm)

import numpy as np
import pandas as pd
import seaborn as sns
import matplotlib.pyplot as plt
from scipy.stats import zscore
from scipy.sparse import issparse

def infer_cnv_by_cluster_with_proper_grouping_plot(
    adata,
    z_thresh=1.5,
    max_cells_per_group=300,
    group_by='leiden',
    verbose=True
):
    adata = adata.copy()
    cluster_labels = adata.obs[group_by].astype(str)
    gene_names = adata.var_names
    cnv_calls = pd.DataFrame(index=adata.obs_names, columns=gene_names)

    for cluster in sorted(cluster_labels.unique()):
        cluster_cells = adata.obs_names[cluster_labels == cluster]
        sub = adata[cluster_cells]
        X = sub.X.toarray() if issparse(sub.X) else sub.X

        if X.shape[0] < 3:
            cnv_calls.loc[cluster_cells] = 'neutral'
            continue

        try:
            zscores = zscore(X, axis=0, nan_policy='omit')
        except Exception as e:
            print(f"Z-score error in cluster {cluster}: {e}")
            zscores = np.zeros_like(X)

        calls = np.where(zscores > z_thresh, 'gain',
                         np.where(zscores < -z_thresh, 'loss', 'neutral'))
        cnv_calls.loc[cluster_cells] = calls

    adata.obsm['cnv_calls'] = cnv_calls
    cnv_calls.index.name = 'cell'
    cnv_calls_reset = cnv_calls.reset_index()
    melted = cnv_calls_reset.melt(id_vars='cell', var_name='gene', value_name='cna')
    melted['cluster'] = cluster_labels.loc[melted['cell']].values
    summary_df = melted.groupby(['cluster', 'cna']).size().unstack(fill_value=0)

    # --- Build matrix for plotting ---
    cell_blocks = []
    ytick_locs = []
    ytick_labels = []

    if {'chromosome', 'start'}.issubset(adata.var.columns):
        adata.var.index.name = 'gene_id'
        gene_ordered = (
            adata.var
            .reset_index()
            .sort_values(by=['chromosome', 'start'])['gene_id']
            .tolist()
        )
    else:
        gene_ordered = list(gene_names)

    for cluster in sorted(cluster_labels.unique()):
        cells_in_group = cluster_labels[cluster_labels == cluster].index
        group_df = cnv_calls.loc[cells_in_group, gene_ordered]

        if group_df.shape[0] > max_cells_per_group:
            group_df = group_df.sample(n=max_cells_per_group, random_state=42)

        numeric = group_df.replace({'gain': 1, 'loss': -1, 'neutral': 0}).astype(float)
        start_row = len(pd.concat(cell_blocks)) if cell_blocks else 0
        ytick_locs.append(start_row + numeric.shape[0] / 2)
        ytick_labels.append(str(cluster))
        cell_blocks.append(numeric)

    cnv_numeric_plot = pd.concat(cell_blocks)

    # Chromosome axis annotation
    chr_midpoints = []
    chr_labels = []
    chr_boundaries = []

    if {'chromosome', 'start'}.issubset(adata.var.columns):
        gene_chr = adata.var.loc[gene_ordered, 'chromosome']
        prev_chr = gene_chr.iloc[0]
        for i, chr in enumerate(gene_chr):
            if chr != prev_chr:
                chr_boundaries.append(i)
                chr_labels.append(prev_chr)
                prev_chr = chr
        chr_boundaries.append(len(gene_chr))
        chr_labels.append(prev_chr)
        chr_midpoints = [(chr_boundaries[i] + chr_boundaries[i + 1]) // 2 for i in range(len(chr_labels) - 1)]

    # --- Plotting ---
    fig, ax = plt.subplots(figsize=(22, 10))
    sns.heatmap(cnv_numeric_plot, cmap='bwr', center=0, ax=ax,
                cbar_kws={'label': 'CNV'}, xticklabels=False, yticklabels=False)

    ax.set_title('CNV Heatmap (inferCNV-style)')
    ax.set_xlabel('Genomic Region (Chromosomes)')
    ax.set_ylabel('Leiden Clusters')

    if chr_midpoints:
        ax.set_xticks(chr_midpoints)
        ax.set_xticklabels(chr_labels[:-1], rotation=90)
        for pos in chr_boundaries:
            ax.axvline(x=pos, color='black', linestyle='--', linewidth=0.4)

    ax.set_yticks(ytick_locs)
    ax.set_yticklabels(ytick_labels, rotation=0)

    plt.tight_layout()
    plt.show()

    return adata, summary_df

data1_final, data1_final_summary = infer_cnv_by_cluster_with_proper_grouping_plot(data1_pca_norm)

cna_bench_final, cna_bench_summary_df = infer_cnv_by_cluster_with_proper_grouping_plot(cna_bench_pca_norm)

def parse_simulated_cnvs(adata):
    import re

    parsed = {}

    for cell, entry in adata.obs['simulated_cnvs'].fillna('').items():
        regions = []
        if entry.strip() == '':
            parsed[cell] = []
            continue

        # Split multiple regions
        parts = entry.split(',')
        for region in parts:
            match = re.match(r'(\w+):(\d+)-(\d+) \(CN (\d+)\)', region.strip())
            if match:
                chrom, start, end, cn = match.groups()
                regions.append({
                    'chromosome': chrom,
                    'start': int(start),
                    'end': int(end),
                    'CN': int(cn)
                })
        parsed[cell] = regions

    return parsed

# Run the parser
sim_cnv_dict = parse_simulated_cnvs(cna_bench_final)

# For example: filter genes on Chr 6

def filter_genes_on_chrno(adata, chromosome_no = '6', start_no = 25435484, end_no = 35035259):
  chromosome_no_genes = adata.var[(adata.var['chromosome'] == chromosome_no) &
                        (adata.var['start'] > start_no) &
                        (adata.var['start'] < end_no)].index

  # Plot average CNV call in these genes per cluster
  cnv_calls = adata.obsm['cnv_calls']  # Your inferred CNVs
  chromosome_no_cnv_summary = cnv_calls[chromosome_no_genes].replace({'gain': 1, 'loss': -1, 'neutral': 0}).astype(float)
  chromosome_no_cnv_summary['leiden'] = adata.obs['leiden']
  chromosome_no_avg = chromosome_no_cnv_summary.groupby('leiden').mean().mean(axis=1)

  print(f"Mean CNV signal on Chr{chromosome_no} simulated region:")
  print(chromosome_no_avg)

filter_genes_on_chrno(cna_bench_final)
filter_genes_on_chrno(cna_bench_final, 'X', 106533974, 112956833)
filter_genes_on_chrno(cna_bench_final, '22', 19807132, 29743868)

"""The reasons why the ChrX has NaN values is because the methodology did not detect genes in that simulated loss region of the ChrX. We can widen the window around to capture nearby genes and see that there is a positive mean signal across all the clusters."""

filter_genes_on_chrno(cna_bench_final, 'X', 100000000, 115000000)

import numpy as np
import pandas as pd
from sklearn.metrics import classification_report, confusion_matrix
import seaborn as sns
import matplotlib.pyplot as plt

def evaluate_cnv_inference(adata, chrom, start, end, label='CNV', verbose=True):
    """
    Evaluate inferred CNVs against simulated CNVs in a specified genomic region.

    Parameters:
    - adata: AnnData object with adata.obsm['cnv_calls'] and adata.obs['simulated_cnvs']
    - chrom: Chromosome (str), e.g. '6', '22', 'X'
    - start, end: Genomic coordinates defining the CNV region
    - label: Name of the region (for titles and logging)
    - verbose: Whether to print a classification report and plot confusion matrix

    Returns:
    - report_df: DataFrame with precision, recall, f1-score for gain/loss/neutral
    """
    # Get genes in region
    region_genes = adata.var[
        (adata.var['chromosome'] == chrom) &
        (adata.var['start'] >= start) &
        (adata.var['start'] <= end)
    ].index

    if len(region_genes) == 0:
        print(f"⚠️ No genes found in region {chrom}:{start}-{end}")
        return None

    # Prepare truth and prediction lists
    y_true, y_pred = [], []
    sim_cnvs = adata.obs['simulated_cnvs'].fillna('')
    inferred = adata.obsm['cnv_calls'][region_genes].copy()

    for cell in inferred.index:
        sim = sim_cnvs[cell]
        for gene in region_genes:
            pred_call = inferred.loc[cell, gene]
            if f"{chrom}:{start}-{end}" in sim:
                if '(CN 0)' in sim or '(CN 1)' in sim:
                    y_true.append('loss')
                elif '(CN 4)' in sim:
                    y_true.append('gain')
                else:
                    y_true.append('neutral')
            else:
                y_true.append('neutral')
            y_pred.append(pred_call)

    # Compute classification metrics
    report = classification_report(y_true, y_pred, labels=['gain', 'loss', 'neutral'], output_dict=True)
    report_df = pd.DataFrame(report).T

    if verbose:
        print(f"\n📊 Performance on {label} ({chrom}:{start}-{end}):")
        print(classification_report(y_true, y_pred, labels=['gain', 'loss', 'neutral']))

        # Confusion matrix plot
        cm = confusion_matrix(y_true, y_pred, labels=['gain', 'loss', 'neutral'])
        sns.heatmap(cm, annot=True, fmt='d', cmap='Blues',
                    xticklabels=['gain', 'loss', 'neutral'],
                    yticklabels=['gain', 'loss', 'neutral'])
        plt.title(f'Confusion Matrix - {label}')
        plt.xlabel('Predicted')
        plt.ylabel('True')
        plt.tight_layout()
        plt.show()

    return report_df

evaluate_cnv_inference(cna_bench_final, '6', 25435484, 35035259, label='Chr6 loss')
evaluate_cnv_inference(cna_bench_final, '22', 19807132, 29743868, label='Chr22 loss')
evaluate_cnv_inference(cna_bench_final, 'X', 106533974, 112956833, label='ChrX gain')

"""ignore below again"""

import numpy as np
import pandas as pd
from scipy.stats import zscore
from scipy.sparse import issparse
import seaborn as sns
import matplotlib.pyplot as plt

def infer_cnv_by_cluster(adata, z_thresh=1.5, max_cells=300, group_by='leiden', verbose=True):
    """
    Infers CNVs per cell by comparing to Leiden cluster mean and plots heatmap.

    Adds:
    - adata.obsm['cnv_calls']: gene-by-cell DataFrame of CNV calls ('gain', 'loss', 'neutral')

    Returns:
    - adata
    - summary_df: count of gains/losses/neutral per cluster
    """
    adata = adata.copy()
    cluster_labels = adata.obs[group_by].astype(str)
    gene_names = adata.var_names

    cnv_calls = pd.DataFrame(index=adata.obs_names, columns=gene_names)

    if verbose:
        print(f"Total clusters: {cluster_labels.nunique()}")

    for cluster in sorted(cluster_labels.unique()):
        cluster_cells = adata.obs_names[cluster_labels == cluster]
        sub = adata[cluster_cells]
        X = sub.X.toarray() if issparse(sub.X) else sub.X

        if X.shape[0] < 3:
            if verbose:
                print(f"Skipping cluster {cluster} (n={X.shape[0]} cells)")
            cnv_calls.loc[cluster_cells] = 'neutral'
            continue

        try:
            zscores = zscore(X, axis=0, nan_policy='omit')
        except Exception as e:
            print(f"Error computing z-score for cluster {cluster}: {e}")
            zscores = np.zeros_like(X)

        calls = np.where(zscores > z_thresh, 'gain',
                         np.where(zscores < -z_thresh, 'loss', 'neutral'))
        cnv_calls.loc[cluster_cells] = calls

        if verbose:
            print(f"Cluster {cluster} done (n={X.shape[0]})")

    # Save CNVs
    adata.obsm['cnv_calls'] = cnv_calls

    # === Summary table ===
    cnv_calls.index.name = 'cell'  # force index to have a name
    cnv_calls_reset = cnv_calls.reset_index()
    melted = cnv_calls_reset.melt(id_vars='cell', var_name='gene', value_name='cna')
    melted['cluster'] = cluster_labels.loc[melted['cell']].values
    summary_df = melted.groupby(['cluster', 'cna']).size().unstack(fill_value=0)

    # === HEATMAP ===
    display_df = cnv_calls.copy()
    display_df['cluster'] = cluster_labels
    display_df = display_df.sort_values('cluster').drop(columns='cluster')

    if display_df.shape[0] > max_cells:
        display_df = display_df.sample(n=max_cells, random_state=42)
        if verbose:
            print(f"Subsampled to {max_cells} cells for heatmap.")

    # Robust gene ordering
    if {'chromosome', 'start'}.issubset(adata.var.columns):
        adata.var.index.name = 'gene_id'
        try:
            ordered_genes = (
                adata.var
                .loc[display_df.columns]
                .reset_index()
                .sort_values(by=['chromosome', 'start'])['gene_id']
                .tolist()
            )
            display_df = display_df[ordered_genes]
        except Exception as e:
            print(f"⚠️ Warning: Could not sort genes by genome. Skipping sort. Reason: {e}")

    # Convert to numeric for heatmap
    cnv_numeric = display_df.replace({'gain': 1, 'loss': -1, 'neutral': 0})

    plt.figure(figsize=(20, 8))
    sns.heatmap(cnv_numeric, cmap='bwr', center=0, cbar_kws={'label': 'CNV'})
    plt.title('CNV Heatmap: Gain (Red), Loss (Blue), Neutral (White)')
    plt.xlabel('Genes')
    plt.ylabel('Cells')
    plt.tight_layout()
    plt.show()

    return adata, summary_df

import numpy as np
import pandas as pd
import seaborn as sns
import matplotlib.pyplot as plt
from scipy.sparse import issparse
from scipy.stats import zscore

def infercnv_style_plot(
    adata,
    group_key='leiden',
    max_cells_per_group=250,
    smooth=True,
    zscore_clip=2.5
):
    """
    Generate an inferCNV-style heatmap.

    Parameters:
    - adata: AnnData with .X and .var['chromosome'], .var['start']
    - group_key: obs key to group cells (e.g. 'leiden' or 'cell_type')
    - max_cells_per_group: limit cells per group for speed/clarity
    - smooth: whether to apply 1D smoothing over genes
    - zscore_clip: clip extreme z-scores (for display)
    """
    # Get expression matrix
    X = adata.X.toarray() if issparse(adata.X) else adata.X.copy()

    # Gene ordering
    genes = adata.var.copy()
    genes.index.name = 'gene_id'
    genes = genes.reset_index()
    genes_sorted = genes.sort_values(by=['chromosome', 'start'])
    gene_order = genes_sorted['gene_id'].values
    gene_idx = adata.var_names.get_indexer(gene_order)
    X = X[:, gene_idx]

    # Z-score across genes (within each cell)
    X = zscore(X, axis=1, nan_policy='omit')
    X = np.clip(X, -zscore_clip, zscore_clip)

    # Optional smoothing
    if smooth:
        from scipy.ndimage import uniform_filter1d
        X = uniform_filter1d(X, size=10, axis=1)

    # Get cell groupings
    cell_groups = adata.obs[group_key].astype(str)
    group_df = pd.DataFrame({'group': cell_groups, 'cell_idx': np.arange(len(cell_groups))})
    group_df = group_df.sort_values('group')

    # Sample and stack per group
    X_rows = []
    row_colors = []
    palette = sns.color_palette('tab20', n_colors=group_df['group'].nunique())
    group_color_map = {g: palette[i] for i, g in enumerate(sorted(group_df['group'].unique()))}

    for group in sorted(group_df['group'].unique()):
        members = group_df[group_df['group'] == group]
        selected = members.sample(n=min(max_cells_per_group, len(members)), random_state=42)
        X_rows.append(X[selected['cell_idx'].values])
        row_colors.extend([group_color_map[group]] * len(selected))

    X_plot = np.vstack(X_rows)

        # === PLOTTING ===
    fig, ax = plt.subplots(figsize=(22, 10))
    sns.heatmap(
        X_plot,
        cmap='bwr',
        center=0,
        xticklabels=False,
        yticklabels=False,
        cbar_kws={'label': 'Z-score'},
        ax=ax
    )

    ax.set_title("inferCNV-style Heatmap: Genes ordered by genome, Cells grouped by " + group_key)
    ax.set_xlabel("Genomic Region (Chromosomes)")
    ax.set_ylabel("Cells (Grouped by " + group_key + ")")

    # === CHROMOSOME X-TICK ANNOTATIONS ===
    gene_chr_series = genes_sorted['chromosome'].values
    chr_boundaries = []
    chr_labels = []
    current_chr = gene_chr_series[0]

    for i, chr in enumerate(gene_chr_series):
        if chr != current_chr:
            chr_boundaries.append(i)
            chr_labels.append(current_chr)
            current_chr = chr

    chr_boundaries.append(len(gene_chr_series))
    chr_labels.append(current_chr)

    # Add vertical lines
    for pos in chr_boundaries:
        ax.axvline(x=pos, color='black', linestyle='--', linewidth=0.4)

    # Add chromosome labels at midpoints
    chr_midpoints = [(chr_boundaries[i] + chr_boundaries[i + 1]) // 2 for i in range(len(chr_boundaries) - 1)]
    ax.set_xticks(chr_midpoints)
    ax.set_xticklabels(chr_labels, rotation=90)

    # === GROUP LABELS ON Y-AXIS ===
    # Calculate group label midpoints for annotation
    group_counts = group_df['group'].value_counts().loc[sorted(group_df['group'].unique())]
    group_sample_counts = [min(count, max_cells_per_group) for count in group_counts]
    group_edges = np.cumsum([0] + group_sample_counts)
    group_mids = [(group_edges[i] + group_edges[i + 1]) // 2 for i in range(len(group_edges) - 1)]

    ax.set_yticks(group_mids)
    ax.set_yticklabels(sorted(group_df['group'].unique()), rotation=0)

    plt.tight_layout()
    plt.show()

import numpy as np
import pandas as pd
import seaborn as sns
import matplotlib.pyplot as plt
from scipy.sparse import issparse
from scipy.stats import zscore
from scipy.ndimage import uniform_filter1d

def infercnv_style_heatmap(
    adata,
    group_key='leiden',
    max_cells_per_group=250,
    smooth=True,
    zscore_clip=2.5
):
    """
    Generate an inferCNV-style heatmap using AnnData input.

    Parameters:
    - adata: AnnData object with .X, .obs[group_key], and .var['chromosome'], .var['start']
    - group_key: obs key to group cells (e.g. 'leiden')
    - max_cells_per_group: maximum number of cells to include per group
    - smooth: whether to apply 1D smoothing over genes
    - zscore_clip: value to clip z-scored expression for color scale
    """
    # === Extract expression matrix ===
    X = adata.X.toarray() if issparse(adata.X) else adata.X.copy()

    # === Sort genes by genome location ===
    genes = adata.var.copy()
    if not {'chromosome', 'start'}.issubset(genes.columns):
        raise ValueError("adata.var must include 'chromosome' and 'start' columns.")
    genes.index.name = 'gene_id'
    genes = genes.reset_index()
    genes_sorted = genes.sort_values(by=['chromosome', 'start'])
    gene_order = genes_sorted['gene_id'].values
    gene_idx = adata.var_names.get_indexer(gene_order)
    X = X[:, gene_idx]

    # === Z-score per cell ===
    X = zscore(X, axis=1, nan_policy='omit')
    X = np.clip(X, -zscore_clip, zscore_clip)

    if smooth:
        X = uniform_filter1d(X, size=10, axis=1)

    # === Group cells ===
    cell_groups = adata.obs[group_key].astype(str)
    group_df = pd.DataFrame({'group': cell_groups, 'cell_idx': np.arange(len(cell_groups))})
    group_df = group_df.sort_values('group')

    # === Subsample cells per group and collect rows ===
    X_rows = []
    row_group_bounds = []
    current_row = 0

    for group in sorted(group_df['group'].unique()):
        members = group_df[group_df['group'] == group]
        selected = members.sample(n=min(max_cells_per_group, len(members)), random_state=42)
        indices = selected['cell_idx'].values
        X_rows.append(X[indices])
        row_group_bounds.append((current_row, current_row + len(indices), group))
        current_row += len(indices)

    X_plot = np.vstack(X_rows)

    # === Plot heatmap ===
    fig, ax = plt.subplots(figsize=(22, 10))
    sns.heatmap(
        X_plot,
        cmap='bwr',
        center=0,
        xticklabels=False,
        yticklabels=False,
        ax=ax,
        cbar_kws={'label': 'Z-score'}
    )

    ax.set_title(f"inferCNV-style Heatmap (Grouped by '{group_key}')")
    ax.set_xlabel("Genomic Region (Chromosomes)")
    ax.set_ylabel("Cells")

    # === Chromosome boundary lines and labels ===
    gene_chr_series = genes_sorted['chromosome'].values
    chr_boundaries = []
    chr_labels = []
    current_chr = gene_chr_series[0]

    for i, chr in enumerate(gene_chr_series):
        if chr != current_chr:
            chr_boundaries.append(i)
            chr_labels.append(current_chr)
            current_chr = chr
    chr_boundaries.append(len(gene_chr_series))
    chr_labels.append(current_chr)

    chr_midpoints = [(chr_boundaries[i] + chr_boundaries[i + 1]) // 2 for i in range(len(chr_labels))]
    ax.set_xticks(chr_midpoints)
    ax.set_xticklabels(chr_labels, rotation=90)

    for pos in chr_boundaries:
        ax.axvline(x=pos, color='black', linestyle='--', linewidth=0.4)

    # === Brackets / labels for clusters on Y-axis ===
    for start, end, group in row_group_bounds:
        ax.hlines([start, end], *ax.get_xlim(), colors='black', linewidth=0.8)
        ax.text(-5, (start + end) / 2, str(group), va='center', ha='right', fontsize=10, fontweight='bold')

    plt.tight_layout()
    plt.show()

data1_cnv, data1_summary = infer_cnv_by_cluster(data1_pca_norm)



cna_bench_cnv, cna_bench_summary = infer_cnv_by_cluster(cna_bench_pca_norm)

def infer_cnv_plot_infercnv_style(adata, z_thresh=1.5, max_cells=300, group_by='leiden', verbose=True):
    import numpy as np
    import pandas as pd
    import seaborn as sns
    import matplotlib.pyplot as plt
    from scipy.stats import zscore
    from scipy.sparse import issparse

    adata = adata.copy()
    cluster_labels = adata.obs[group_by].astype(str)
    gene_names = adata.var_names
    cnv_calls = pd.DataFrame(index=adata.obs_names, columns=gene_names)

    for cluster in sorted(cluster_labels.unique()):
        cluster_cells = adata.obs_names[cluster_labels == cluster]
        sub = adata[cluster_cells]
        X = sub.X.toarray() if issparse(sub.X) else sub.X

        if X.shape[0] < 3:
            cnv_calls.loc[cluster_cells] = 'neutral'
            continue

        try:
            zscores = zscore(X, axis=0, nan_policy='omit')
        except Exception as e:
            print(f"Z-score error in cluster {cluster}: {e}")
            zscores = np.zeros_like(X)

        calls = np.where(zscores > z_thresh, 'gain',
                         np.where(zscores < -z_thresh, 'loss', 'neutral'))
        cnv_calls.loc[cluster_cells] = calls

    adata.obsm['cnv_calls'] = cnv_calls
    cnv_calls.index.name = 'cell'
    cnv_calls_reset = cnv_calls.reset_index()
    melted = cnv_calls_reset.melt(id_vars='cell', var_name='gene', value_name='cna')
    melted['cluster'] = cluster_labels.loc[melted['cell']].values
    summary_df = melted.groupby(['cluster', 'cna']).size().unstack(fill_value=0)

    display_df = cnv_calls.copy()
    display_df['cluster'] = cluster_labels
    display_df = display_df.sort_values('cluster').drop(columns='cluster')

    if display_df.shape[0] > max_cells:
        display_df = display_df.sample(n=max_cells, random_state=42)
        if verbose:
            print(f"Subsampled to {max_cells} cells for heatmap.")

    chr_boundaries, chr_labels, gene_ordered = [], [], display_df.columns.tolist()
    if {'chromosome', 'start'}.issubset(adata.var.columns):
        try:
            adata.var.index.name = 'gene_id'
            genes_sorted = (
                adata.var
                .loc[display_df.columns]
                .reset_index()
                .sort_values(by=['chromosome', 'start'])
            )
            gene_ordered = genes_sorted['gene_id'].tolist()
            display_df = display_df[gene_ordered]

            gene_chr_series = genes_sorted['chromosome'].values
            current_chr = gene_chr_series[0]
            for i, chr in enumerate(gene_chr_series):
                if chr != current_chr:
                    chr_boundaries.append(i)
                    chr_labels.append(current_chr)
                    current_chr = chr
            chr_boundaries.append(len(gene_chr_series))  # end of last chromosome
            chr_labels.append(current_chr)  # add label for last chromosome
        except Exception as e:
            print(f"⚠️ Warning: Could not sort genes by genome. Skipping sort. Reason: {e}")

    cnv_numeric = display_df.replace({'gain': 1, 'loss': -1, 'neutral': 0}).astype(float)

    fig, ax = plt.subplots(figsize=(22, 10))
    sns.heatmap(cnv_numeric, cmap='bwr', center=0, ax=ax,
                cbar_kws={'label': 'CNV'}, xticklabels=False, yticklabels=False)

    ax.set_title('CNV Heatmap (inferCNV-style)')
    ax.set_xlabel('Genomic Region (Chromosomes)')
    ax.set_ylabel('Cells')

    if chr_labels and len(chr_boundaries) == len(chr_labels):
        chr_midpoints = [(chr_boundaries[i] + chr_boundaries[i + 1]) // 2 for i in range(len(chr_labels))]
        ax.set_xticks(chr_midpoints)
        ax.set_xticklabels(chr_labels[:-1], rotation=90)
        for pos in chr_boundaries[:-1]:
            ax.axvline(x=pos, color='black', linestyle='--', linewidth=0.4)

    # Horizontal lines to group by Leiden clusters
    cluster_order = display_df.index.to_series().map(cluster_labels)
    cluster_ordered = cluster_order.loc[display_df.index]
    changes = cluster_ordered.ne(cluster_ordered.shift()).cumsum()
    group_lines = cluster_ordered.groupby(changes).apply(lambda x: x.index[0])

    for line in group_lines[1:]:
        ax.axhline(y=line, color='black', linestyle='-', linewidth=1)

    plt.tight_layout()
    plt.show()

    return adata, summary_df

cna_bench_final, cna_bench_final_summary = infercnv_style_plot(data1_pca_norm)

def parse_simulated_cnvs(adata):
    import re

    parsed = {}

    for cell, entry in adata.obs['simulated_cnvs'].fillna('').items():
        regions = []
        if entry.strip() == '':
            parsed[cell] = []
            continue

        # Split multiple regions
        parts = entry.split(',')
        for region in parts:
            match = re.match(r'(\w+):(\d+)-(\d+) \(CN (\d+)\)', region.strip())
            if match:
                chrom, start, end, cn = match.groups()
                regions.append({
                    'chromosome': chrom,
                    'start': int(start),
                    'end': int(end),
                    'CN': int(cn)
                })
        parsed[cell] = regions

    return parsed

# Run the parser
sim_cnv_dict = parse_simulated_cnvs(cna_bench_final)

# For example: filter genes on Chr 6

def filter_genes_on_chr6(adata):
  chr6_genes = adata.var[(adata.var['chromosome'] == '6') &
                        (adata.var['start'] > 25435484) &
                        (adata.var['start'] < 35035259)].index

  # Plot average CNV call in these genes per cluster
  cnv_calls = adata.obsm['cnv_calls']  # Your inferred CNVs
  chr6_cnv_summary = cnv_calls[chr6_genes].replace({'gain': 1, 'loss': -1, 'neutral': 0}).astype(float)
  chr6_cnv_summary['leiden'] = adata.obs['leiden']
  chr6_avg = chr6_cnv_summary.groupby('leiden').mean().mean(axis=1)

  print("Mean CNV signal on Chr6 simulated loss region:")
  print(chr6_avg)

filter_genes_on_chr6(cna_bench_final)

def extract_cnv_regions(adata, group_by_cell=True, min_genes=3):
    """
    Extract contiguous CNV regions per cell or cluster from adata.obsm['cnv_calls'].

    Requires:
    - adata.var['chromosome']
    - adata.var['start']

    Parameters:
    - group_by_cell: if True, returns CNVs per cell; else by leiden cluster
    - min_genes: minimum # of consecutive genes to consider a region

    Returns:
    - cnv_regions: list of dicts [{cell/cluster, chromosome, start, end, type}]
    """
    assert 'cnv_calls' in adata.obsm, "Missing CNA calls"
    assert {'chromosome', 'start'}.issubset(adata.var.columns), "Gene positions missing in .var"

    # Sort genes by genomic position
    gene_order = adata.var.reset_index().sort_values(by=['chromosome', 'start'])
    gene_list = gene_order['index'].values

    cnv_df = adata.obsm['cnv_calls'][gene_list]  # order columns (genes)

    if not group_by_cell:
        assert 'leiden' in adata.obs.columns, "Missing cluster labels"
        cnv_df = cnv_df.copy()
        cnv_df['cluster'] = adata.obs['leiden']
        cnv_df = cnv_df.groupby('cluster').agg(lambda x: x.mode()[0] if not x.isna().all() else 'neutral')

    cnv_regions = []

    for cell_or_cluster, row in cnv_df.iterrows():
        prev_state = None
        region_start = None
        region_genes = []

        for gene in gene_list:
            state = row[gene]
            chrom = adata.var.loc[gene, 'chromosome']
            pos = adata.var.loc[gene, 'start']

            if state == prev_state and state in ('gain', 'loss'):
                region_genes.append((gene, chrom, pos))
            else:
                if prev_state in ('gain', 'loss') and len(region_genes) >= min_genes:
                    region_chrom = region_genes[0][1]
                    region_start = region_genes[0][2]
                    region_end = region_genes[-1][2]
                    cnv_regions.append({
                        'group': cell_or_cluster,
                        'chromosome': region_chrom,
                        'start': region_start,
                        'end': region_end,
                        'type': prev_state
                    })
                region_genes = [(gene, chrom, pos)] if state in ('gain', 'loss') else []
            prev_state = state

        # Catch final region
        if prev_state in ('gain', 'loss') and len(region_genes) >= min_genes:
            cnv_regions.append({
                'group': cell_or_cluster,
                'chromosome': region_genes[0][1],
                'start': region_genes[0][2],
                'end': region_genes[-1][2],
                'type': prev_state
            })

    return cnv_regions

"""ignore below

"""

from scipy.stats import zscore

def infer_cnv_by_cluster(adata, z_thresh=1.5):

    adata = adata.copy()
    cluster_labels = adata.obs['leiden'].astype(str)
    gene_names = adata.var_names

    # Compute average expression per gene per cluster
    cluster_means = (
        pd.DataFrame(adata.X.toarray() if hasattr(adata.X, "toarray") else adata.X,
                     index=adata.obs_names, columns=gene_names)
        .groupby(cluster_labels)
        .mean()
    )

    # Initialize CNV calls: gain, loss, or neutral
    cnv_calls = pd.DataFrame(index=adata.obs_names, columns=gene_names)

    for cluster in cluster_means.index:
        cluster_cells = adata.obs_names[cluster_labels == cluster]
        cluster_expr = adata[cluster_cells].X.toarray() if hasattr(adata.X, "toarray") else adata[cluster_cells].X

        # Compare each cell's expression to cluster mean → z-score per gene
        zscores = zscore(cluster_expr, axis=0)
        calls = np.where(zscores > z_thresh, 'gain',
                         np.where(zscores < -z_thresh, 'loss', 'neutral'))

        cnv_calls.loc[cluster_cells] = calls

    # Save CNV calls to .obsm
    adata.obsm['cnv_calls'] = cnv_calls

    # Optional: Summarize by cell type (Leiden) and CNA state
    melted = cnv_calls.reset_index().melt(id_vars='index', var_name='gene', value_name='cna')
    melted['cluster'] = cluster_labels.loc[melted['index']].values
    summary_df = melted.groupby(['cluster', 'cna']).size().unstack(fill_value=0)

    return adata, summary_df

# Run for each dataset
data1_cnv, data1_summary = infer_cnv_by_cluster(data1_pca_norm)
cna_bench_cnv, cna_bench_summary = infer_cnv_by_cluster(cna_bench_pca_norm)

def perform_cna_inference(adata, threshold=1.0):
    # Step 1: Get the cluster labels from Leiden clustering
    # Assuming Leiden clustering is already performed and stored in adata.obs['leiden']

    # Step 2: Calculate the average expression for each cluster
    cluster_references = {}
    for cluster in adata.obs['leiden'].unique():
        # Select cells from the current cluster
        cluster_cells = adata[adata.obs['leiden'] == cluster]

        # Calculate the average expression for each gene in the cluster
        cluster_avg_expr = np.mean(cluster_cells.X.toarray(), axis=0)
        cluster_references[cluster] = cluster_avg_expr

    # Step 3: Initialize CNA calls (default as 'No CNA')
    adata.obs['cna_calls'] = 'No CNA'  # Initialize as 'No CNA'

    # Step 4: Compare each cell's expression with its cluster reference
    for cluster in adata.obs['leiden'].unique():
        # Get the cells in the current cluster
        cluster_cells = adata[adata.obs['leiden'] == cluster]
        # Get the cluster's reference expression (average expression)
        cluster_reference = cluster_references[cluster]

        for cell_idx, cell in enumerate(cluster_cells.X):
            # Convert sparse matrix to dense format and flatten the array for easy manipulation
            cell_dense = cell.toarray().flatten()
            # Calculate fold-change (log2 of cell expression / cluster reference)
            fold_change = np.log2(cell_dense / cluster_reference)

            # Step 5: Identify 'Gain' or 'Loss' based on threshold
            if np.any(fold_change > threshold):
                adata.obs.at[cell_idx, 'cna_calls'] = 'Gain'
            elif np.any(fold_change < -threshold):
                adata.obs.at[cell_idx, 'cna_calls'] = 'Loss'

    # Step 6: Visualize the result (CNA detection)
    sc.pl.umap(adata, color='cna_calls', title='CNA Detection Based on Cluster References')

    return adata

# Example usage:
data1_pca_norm = perform_cna_inference(data1_pca_norm, threshold=1.0)
cna_bench_pca_norm = perform_cna_inference(cna_bench_pca_norm, threshold=1.0)

# Visualize UMAP and check the CNA detection
sc.pl.umap(data1_pca_norm, color='cna_calls', title='CNA Detection for data1')
sc.pl.umap(cna_bench_pca_norm, color='cna_calls', title='CNA Detection for cna_bench')

# Print CNA calls to see the distribution of gains, losses, and no CNAs
print(data1_pca_norm.obs['cna_calls'].value_counts())
print(cna_bench_pca_norm.obs['cna_calls'].value_counts())

import numpy as np

def smooth_expression_by_cluster(adata, window_size=50):
    """
    Smooth gene expression for each cluster separately using a sliding window approach.
    The smoothed expression is calculated within each cluster.

    Parameters:
    - adata: AnnData object with the expression matrix and Leiden clustering in `adata.obs['leiden']`.
    - window_size: The size of the window for smoothing.

    Returns:
    - smoothed_expression: The smoothed gene expression matrix.
    """

    # Create a copy of the original data
    if 'counts' in adata.layers:
        adata.raw = adata.copy()
        adata.X = adata.layers['counts'].copy()

    # Remove genes with missing chromosome
    adata = adata[:, np.where(adata.var['chromosome'].notna())[0]].copy()
    adata.var = adata.var.sort_values(by=['chromosome', 'start'])  # Sort genes by chromosome and position

    smoothed = []

    # Loop over each cluster
    clusters = adata.obs['leiden'].unique()
    for cluster in clusters:
        cluster_cells = adata[adata.obs['leiden'] == cluster]

        smoothed_cluster = []
        num_genes = adata.var.shape[0]

        # Loop through each gene in the cluster and apply smoothing
        for i in range(num_genes):
            window_start = max(0, i - window_size // 2)
            window_end = min(num_genes, i + window_size // 2 + 1)

            # Calculate the mean expression for each cell in the cluster for the window
            smoothed_expr = np.mean(cluster_cells.X[:, window_start:window_end], axis=1)
            smoothed_cluster.append(smoothed_expr)

        # Stack the smoothed expressions for the cluster
        smoothed_cluster_array = np.array(smoothed_cluster).T  # Transpose to match the expected shape
        smoothed.append(smoothed_cluster_array)

    # Stack all clusters' smoothed expressions
    smoothed_expression = np.vstack(smoothed)

    # Return the smoothed expression as a sparse matrix
    return smoothed_expression

# Apply the cluster-based smoothing
data1_smooth = smooth_expression_by_cluster(data1_pca_norm, window_size=50)

# Assign the smoothed expression back to the AnnData object
adata_smooth = data1_pca_norm.copy()
adata_smooth.X = data1_smooth

# Now you can proceed with CNA inference or any other analysis

from scipy.sparse import csr_matrix

def smooth_expression_within_cluster(adata, window_size=50):
    smoothed = []
    clusters = adata.obs['leiden'].unique()

    for cluster in clusters:
        cluster_cells = adata[adata.obs['leiden'] == cluster]

        smoothed_cluster = []
        num_genes = cluster_cells.var.shape[0]

        for i in range(num_genes):
            window_start = max(0, i - window_size // 2)
            window_end = min(num_genes, i + window_size // 2 + 1)

            window_expression = cluster_cells.X[:, window_start:window_end]
            smoothed_expr = window_expression.mean(axis=1).A1
            smoothed_cluster.append(smoothed_expr)

        smoothed_cluster_array = np.array(smoothed_cluster).T
        smoothed.append(smoothed_cluster_array)

    smoothed_expression = np.vstack(smoothed)

    smoothed_expression_sparse = csr_matrix(smoothed_expression)

    adata_smooth = adata.copy()


    return adata_smooth

data1_smooth = smooth_expression_within_cluster(data1_pca_norm)

# Check if adata_smooth is still an AnnData object
print(f"adata_smooth type: {type(data1_smooth)}")  # Should print: <class 'anndata.core.anndata.AnnData'>

# Check if obs and var are intact
print(f"adata_smooth.obs shape: {data1_smooth.obs.shape}")  # Should match the number of cells
print(f"adata_smooth.var shape: {data1_smooth.var.shape}")  # Should match the number of genes

# Check if 'leiden' column is still present in 'obs'
if 'leiden' in data1_smooth.obs:
    print("Leiden clustering column exists in adata_smooth.obs")
else:
    print("Leiden clustering column is missing from adata_smooth.obs")

# Print the first few rows of the obs DataFrame to inspect the metadata
print(data1_smooth.obs.head())

# Verify that smoothed expression is correctly set (check the number of cells and genes)
print(f"Smoothed expression matrix shape: {data1_smooth.X.shape}")  # Should match the number of cells and genes

# Check if the smoothed expression matrix is sparse
print(f"Smoothed expression type: {type(data1_smooth.X)}")  # Should be a sparse matrix (likely csr_matrix or csc_matrix)

print(cna_bench_pca_norm.shape)

cna_bench_smooth = smooth_expression_within_cluster(cna_bench_pca_norm)

print(cna_bench_smooth.shape)

print(data1_smooth.shape)  # Check the shape of the smoothed data
print(data1_smooth)  # Inspect the smoothed sparse matrix
print(data1_pca_norm.shape)

def perform_cna_inference_with_smoothed_expression(adata, threshold=1.0):
    # No need to add smoothed expression to adata.obsm
    # adata.obsm['smoothed_expression'] = smoothed_expression   # Skip this line if not needed

    cluster_references = {}
    for cluster in adata.obs['leiden'].unique():
        cluster_cells = adata[adata.obs['leiden'] == cluster]
        cluster_avg_expr = np.mean(cluster_cells.X.toarray(), axis=0)
        cluster_references[cluster] = cluster_avg_expr

    adata.obs['cna_calls'] = 'No CNA'  # Initialize as 'No CNA'

    for cluster in adata.obs['leiden'].unique():
        cluster_cells = adata[adata.obs['leiden'] == cluster]
        cluster_reference = cluster_references[cluster]

        for cell_idx, cell in enumerate(cluster_cells.X):
            cell_dense = cell.toarray().flatten()
            fold_change = np.log2(cell_dense / cluster_reference)

            # Identify gain or loss based on the threshold
            if np.any(fold_change > threshold):
                adata.obs.at[cell_idx, 'cna_calls'] = 'Gain'
            elif np.any(fold_change < -threshold):
                adata.obs.at[cell_idx, 'cna_calls'] = 'Loss'

    # Step 4: Visualize the result (CNA detection)
    sc.pl.umap(adata, color='cna_calls', title='CNA Detection Based on Cluster References')

    return adata

data1_final = perform_cna_inference_with_smoothed_expression(data1_smooth, threshold=1.0)

data1_final = perform_cna_inference_with_smoothed_expression(data1_smooth, threshold=1.0)
cna_bench_final = perform_cna_inference_with_smoothed_expression(cna_bench_smooth, threshold=1.0)

print(data1_smooth.shape)  # Check the shape of the smoothed data
print(data1_smooth)  # Inspect the smoothed sparse matrix
print(data1_pca_norm.shape)

from scipy.sparse import csr_matrix
import numpy as np

def perform_cna_inference_with_smoothed_expression(adata, smoothed_expression, threshold=1.0):
    # Ensure smoothed expression has the same shape as the original expression matrix
    smoothed_expression_sparse = csr_matrix(smoothed_expression)

    # Ensure smoothed expression is of the correct shape
    print(f"Smoothed expression shape: {smoothed_expression_sparse.shape}")
    print(f"adata shape: {adata.shape}")

    # Step 1: Assign smoothed expression to the AnnData object
    adata.obsm['smoothed_expression'] = smoothed_expression_sparse

    # Initialize a dictionary for cluster-specific references
    cluster_references = {}

    # Calculate the cluster average expression (reference) for each cluster
    for cluster in adata.obs['leiden'].unique():
        cluster_cells = adata[adata.obs['leiden'] == cluster]
        cluster_avg_expr = np.array(cluster_cells.X.mean(axis=0)).flatten()
        cluster_references[cluster] = cluster_avg_expr

    # Initialize the 'cna_calls' column to 'No CNA' for all cells
    adata.obs['cna_calls'] = 'No CNA'

    # Step 2: Perform CNA inference for each cluster
    for cluster in adata.obs['leiden'].unique():
        cluster_cells = adata[adata.obs['leiden'] == cluster]
        cluster_reference = cluster_references[cluster]

        # Step 3: Check each cell in the cluster
        for cell_idx, cell in enumerate(cluster_cells.X):
            cell_dense = cell.toarray().flatten()
            fold_change = np.log2(cell_dense / cluster_reference)

            # Identify CNA (Gain or Loss) based on fold change and threshold
            if np.any(fold_change > threshold):
                adata.obs.at[cell_idx, 'cna_calls'] = 'Gain'
            elif np.any(fold_change < -threshold):
                adata.obs.at[cell_idx, 'cna_calls'] = 'Loss'

    # Step 4: Visualize the results
    sc.pl.umap(adata, color='cna_calls', title='CNA Detection Based on Cluster References')

    return adata

# Example usage:
data1_pca_norm = perform_cna_inference_with_smoothed_expression(data1_pca_norm, data1_smooth, threshold=1.0)
cna_bench_pca_norm = perform_cna_inference_with_smoothed_expression(cna_bench_pca_norm, cna_bench_smooth, threshold=1.0)

# Apply the CNA inference with smoothed expression data
data1_pca_norm = perform_cna_inference_with_smoothed_expression(data1_pca_norm, data1_smooth, threshold=1.0)
cna_bench_pca_norm = perform_cna_inference_with_smoothed_expression(cna_bench_pca_norm, cna_bench_smooth, threshold=1.0)

# Visualize UMAP and check the CNA detection
sc.pl.umap(data1_pca_norm, color='cna_calls', title='CNA Detection for data1')
sc.pl.umap(cna_bench_pca_norm, color='cna_calls', title='CNA Detection for cna_bench')

# Print CNA calls to see the distribution of gains, losses, and no CNAs
print(data1_pca_norm.obs['cna_calls'].value_counts())
print(cna_bench_pca_norm.obs['cna_calls'].value_counts())



print(f"Number of cells in data1_pca_norm: {data1_pca_norm.shape[0]}")
print(f"Number of cells in cna_bench_pca_norm: {cna_bench_pca_norm.shape[0]}")

# After performing the CNA inference, check the counts of CNA calls
print("CNA calls distribution for data1_pca_norm:")
print(data1_pca_norm.obs['cna_calls'].value_counts())

print(data1_pca_norm.obs.columns)